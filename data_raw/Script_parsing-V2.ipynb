{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import re\n",
    "import bleach\n",
    "import random\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_CHARACTER = \"ROSS\"\n",
    "class Line: \n",
    "    def __init__ (self, speaker, line):\n",
    "        self.speaker = speaker\n",
    "        self.line = line\n",
    "\n",
    "    def __str__ (self):\n",
    "        return self.speaker + \": \" + self.line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_line(line):\n",
    "    step1 = line.strip()\n",
    "    step2 = re.sub(r'\\([^)]*\\)',\"\", step1)\n",
    "    return step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pairs(lines):\n",
    "    scene_characters = {}\n",
    "    lines_structured = []\n",
    "    for l in lines:\n",
    "        l_fields = l.split(\":\")\n",
    "        if len(l_fields) == 1:\n",
    "            continue\n",
    "            \n",
    "        character = l_fields[0].strip().upper()\n",
    "        if character not in scene_characters:\n",
    "            scene_characters[character] = 0\n",
    "        scene_characters[character] += 1\n",
    "        character_words = l_fields[1].strip()\n",
    "        lines_structured.append(Line(character, character_words))\n",
    "        \n",
    "    if TARGET_CHARACTER not in scene_characters:\n",
    "        return []\n",
    "    \n",
    "    line_pairs = []\n",
    "    prev_line = lines_structured[0]\n",
    "    for l in lines_structured[1:]:\n",
    "        if l.speaker == TARGET_CHARACTER:\n",
    "            line_pairs.append((prev_line, l))\n",
    "        elif l.speaker == \"ALL\" and prev_line.speaker != TARGET_CHARACTER:\n",
    "            l_new = Line(TARGET_CHARACTER, l.line)\n",
    "            line_pairs.append((prev_line, l_new))\n",
    "            \n",
    "        elif TARGET_CHARACTER in l.speaker and prev_line.speaker != TARGET_CHARACTER:\n",
    "            l_new = Line(TARGET_CHARACTER, l.line)\n",
    "            line_pairs.append((prev_line, l_new))\n",
    "        prev_line = l \n",
    "    \n",
    "    return line_pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairs_to_string(pairs):\n",
    "    ret = \"\"\n",
    "    for (p1, p2) in pairs:\n",
    "        ret += str(p1.line) + \" <+++++> \" + str(p2.line) + \"\\n\"\n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_file(file_name):\n",
    "    f = open(file_name, 'r', encoding = \"ISO-8859-1\")\n",
    "    f_contents = f.read()\n",
    "    f.close()\n",
    "    scenes = re.compile(\"\\[.*\\]\").split(f_contents)\n",
    "    \n",
    "    pairs_from_file = \"\"\n",
    "    for scene in scenes:\n",
    "        scene_strip = scene.strip()\n",
    "        if scene_strip == \"\":\n",
    "            continue \n",
    "        scene_lines = scene.split(\"\\n\")\n",
    "        processed_lines = []\n",
    "        for l in scene_lines:\n",
    "            tmp = process_line(l)\n",
    "            if tmp != \"\":\n",
    "                processed_lines.append(tmp)\n",
    "        line_pairs = make_pairs(processed_lines)\n",
    "        pairs_txt = pairs_to_string(line_pairs)\n",
    "        pairs_from_file += pairs_txt\n",
    "    return pairs_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = os.listdir(\"scripts/\")\n",
    "all_data = open(\"Ross_responses.txt\", 'w')\n",
    "for s in scripts:\n",
    "    file_data = process_file(\"scripts/\" + s)\n",
    "    if file_data == None:\n",
    "        continue\n",
    "    all_data.write(file_data)\n",
    "all_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition data into 3 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8719\n"
     ]
    }
   ],
   "source": [
    "def divide_data():\n",
    "    f = open(\"Ross_responses.txt\", 'r', encoding = \"ISO-8859-1\")\n",
    "    data = f.read().split(\"\\n\")[:-1]\n",
    "    print(len(data))\n",
    "    random.Random(1776).shuffle(data)\n",
    "    #8719 pieces of data\n",
    "    test_data = data[:1000]\n",
    "    valid_data = data[1000:3000]\n",
    "    train_data = data[3000:]\n",
    "    \n",
    "    test_file = open(\"Ross_test.txt\", 'w')\n",
    "    for d in test_data:\n",
    "        test_file.write(d+\"\\n\")\n",
    "    test_file.close()\n",
    "    \n",
    "    valid_file = open(\"Ross_valid.txt\", 'w')\n",
    "    for d in valid_data:\n",
    "        valid_file.write(d+\"\\n\")\n",
    "    valid_file.close()\n",
    "    \n",
    "    train_file = open(\"Ross_train.txt\", 'w')\n",
    "\n",
    "divide_data()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1743.8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8719/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [0,1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
