{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import html2text\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cornell movie-dialogs corpus/movie_lines.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c10ec3ff6436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlines_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cornell movie-dialogs corpus/movie_lines.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlines_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mall_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cornell movie-dialogs corpus/movie_lines.txt'"
     ]
    }
   ],
   "source": [
    "lines_filename = \"cornell movie-dialogs corpus/movie_lines.txt\"\n",
    "lines_file = open(lines_filename, 'r', encoding = \"ISO-8859-1\")\n",
    "all_lines = lines_file.read()\n",
    "lines = all_lines.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines_simple = {}\n",
    "i = 0\n",
    "for l in lines:\n",
    "    line_fields = l.split(\"+++$+++\")\n",
    "    i += 1\n",
    "    try:\n",
    "        line_ID = line_fields[0].strip()\n",
    "        #character_name  = line_fields[3].strip()\n",
    "        character_phrase = line_fields[4].strip()\n",
    "        \n",
    "        #char_line = character_name + \": \" + character_phrase\n",
    "        lines_simple[line_ID] = character_phrase\n",
    "        \n",
    "    except: \n",
    "        print(\"Problem with %d th line \\n\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shorten lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shorten_pair(pair):\n",
    "    (query, reply) = pair\n",
    "    query_sentences = sent_tokenize(query)\n",
    "    reply_sentences = sent_tokenize(reply)\n",
    "\n",
    "    new_input = \"\"\n",
    "    num_input = 0\n",
    "    for s in reversed(query_sentences):\n",
    "        s_tokens = word_tokenize(s)\n",
    "        if num_input + len(s_tokens) <= 30:\n",
    "            new_input = s + \" \" + new_input\n",
    "            num_input += len(s_tokens)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    new_input = new_input.strip()\n",
    "\n",
    "    new_reply = \"\"\n",
    "    num_reply = 0\n",
    "    for s in reply_sentences:\n",
    "        s_tokens = word_tokenize(s)\n",
    "        if num_reply + len(s_tokens) <= 30:\n",
    "            new_reply = new_reply + \" \" + s\n",
    "            num_reply += len(s_tokens)\n",
    "        else:\n",
    "            break\n",
    "    new_reply = new_reply.strip()\n",
    "\n",
    "    return (new_input,new_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Re-create conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_filename = \"cornell movie-dialogs corpus/movie_conversations.txt\"\n",
    "conv_file = open(conv_filename, 'r', encoding=\"ISO-8859-1\")\n",
    "all_conv = conv_file.read()\n",
    "conv = all_conv.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_tmp = conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221616\n"
     ]
    }
   ],
   "source": [
    "out_file = open(\"Cornell_all.txt\", 'w')\n",
    "\n",
    "total = 0\n",
    "for c in conv_tmp:\n",
    "    c_fields = c.split(\"+++$+++\")\n",
    "    if len(c_fields) < 4:\n",
    "        continue\n",
    "    c_lines = c_fields[3].strip()[1:-1].split(\",\")\n",
    "    \n",
    "    for i in range(len(c_lines)-1):\n",
    "        query = lines_simple[c_lines[i].strip(' \\'')]\n",
    "        reply = lines_simple[c_lines[i+1].strip(' \\'')]\n",
    "        #(new_query, new_reply) = shorten_pair((query, reply))\n",
    "        if 'xxxxxx' in query or 'xxxxxx' in reply:\n",
    "            continue \n",
    "        out_file.write(query + \" <+++++> \" + reply + \"\\n\")\n",
    "    \n",
    "    total += len(c_lines) - 1\n",
    "print(total)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
